{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Hope_Speech_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amolgupta7/Hope-Speech-Detection/blob/main/Final_Hope_Speech_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install humanfriendly\n",
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vz4sFEZUBAWF",
        "outputId": "69499845-86fa-428b-db94-3894d4fd0dde"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: humanfriendly in /usr/local/lib/python3.7/dist-packages (10.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.5.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bqmPsi6RvG5V"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import drive \n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification, RobertaModel, RobertaConfig\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from humanfriendly import format_timespan\n",
        "from datasets import load_metric\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the GPU, if found.\n",
        "\n"
      ],
      "metadata": {
        "id": "a5zazwGewoom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "9gr1lbOWxT92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "35c05d19-9a70-402d-d2cc-59a4633badc1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla K80'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mounting the drive to load the data from the drive."
      ],
      "metadata": {
        "id": "9XjYqrCaxcPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive') #Connecting to drive."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQpxfVFnzDwo",
        "outputId": "27a2fa72-f21b-4329-e20b-56ac59ff23fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the dataset. Path can be altered"
      ],
      "metadata": {
        "id": "pYRNLL4mxx0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"drive/MyDrive/Codalab/HopeSpeech Detection For Equality, Diversity and, Inclusion\""
      ],
      "metadata": {
        "id": "UKnhMwZox5_a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(os.path.join(path,\"Hope_ENG_train.csv\")) \n",
        "df_dev = pd.read_csv(os.path.join(path,\"Hope_ENG_dev.csv\"))\n",
        "df_test = pd.read_csv(os.path.join(path,\"Hope_ENG_test.csv\"))"
      ],
      "metadata": {
        "id": "6uBf2uSVzM3D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_DHgfNn3zhrB",
        "outputId": "8f8b68eb-0ec8-44e2-b0f7-9395bd4ec711"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Texts            label\n",
              "18431  @Adrian Bingham  It's definately not the bigge...  Non_hope_speech\n",
              "3263   @Evelyne b prayer and faith are the only thing...  Non_hope_speech\n",
              "5427   Francesca nnAll these problems that they ran i...  Non_hope_speech\n",
              "14980  OMG I love Crystal’s innocence! She is such a ...      Hope_speech\n",
              "19944                                        @THIS IS ME  Non_hope_speech\n",
              "21994  She's not well is she. Souless hate is not a g...  Non_hope_speech\n",
              "4280      @colorbar.s she literally came out as bisexual      Hope_speech\n",
              "2600                THEIR JEANS ARE EVEN CUFFED LIKE WTF  Non_hope_speech\n",
              "5592   BS wasted conversation perpetuating the racism...  Non_hope_speech\n",
              "12817    Nobody expects the overused Monty Python quote!  Non_hope_speech"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-679cb3f9-5c99-4c82-8616-f2b1155c3867\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18431</th>\n",
              "      <td>@Adrian Bingham  It's definately not the bigge...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3263</th>\n",
              "      <td>@Evelyne b prayer and faith are the only thing...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5427</th>\n",
              "      <td>Francesca nnAll these problems that they ran i...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14980</th>\n",
              "      <td>OMG I love Crystal’s innocence! She is such a ...</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19944</th>\n",
              "      <td>@THIS IS ME</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21994</th>\n",
              "      <td>She's not well is she. Souless hate is not a g...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4280</th>\n",
              "      <td>@colorbar.s she literally came out as bisexual</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2600</th>\n",
              "      <td>THEIR JEANS ARE EVEN CUFFED LIKE WTF</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5592</th>\n",
              "      <td>BS wasted conversation perpetuating the racism...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12817</th>\n",
              "      <td>Nobody expects the overused Monty Python quote!</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-679cb3f9-5c99-4c82-8616-f2b1155c3867')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-679cb3f9-5c99-4c82-8616-f2b1155c3867 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-679cb3f9-5c99-4c82-8616-f2b1155c3867');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "cK-yxqi_zp5t",
        "outputId": "46190511-b37a-4528-cebd-b4b1501c4686"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Texts            label\n",
              "125               She maybe thinks she is caucasian lol  Non_hope_speech\n",
              "932   Just because she said she isn’t okay with Homo...  Non_hope_speech\n",
              "2001                                  All life's matter      Hope_speech\n",
              "1817  Finally our history is out of the shadows. Bla...  Non_hope_speech\n",
              "1278                 By the way I think she looks great  Non_hope_speech\n",
              "2144                               Ketnipz They assumed  Non_hope_speech\n",
              "1121                      I was so SURE about that like  Non_hope_speech\n",
              "1726  @Suicide Booth but these idiots miss that out ...  Non_hope_speech\n",
              "1054                                       Turn off fox  Non_hope_speech\n",
              "2527        Should we tell them about the past popes...  Non_hope_speech"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dcfa0d1-df26-42d9-aea3-128f438d39e6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>She maybe thinks she is caucasian lol</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>Just because she said she isn’t okay with Homo...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2001</th>\n",
              "      <td>All life's matter</td>\n",
              "      <td>Hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1817</th>\n",
              "      <td>Finally our history is out of the shadows. Bla...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>By the way I think she looks great</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2144</th>\n",
              "      <td>Ketnipz They assumed</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1121</th>\n",
              "      <td>I was so SURE about that like</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1726</th>\n",
              "      <td>@Suicide Booth but these idiots miss that out ...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1054</th>\n",
              "      <td>Turn off fox</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2527</th>\n",
              "      <td>Should we tell them about the past popes...</td>\n",
              "      <td>Non_hope_speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dcfa0d1-df26-42d9-aea3-128f438d39e6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dcfa0d1-df26-42d9-aea3-128f438d39e6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dcfa0d1-df26-42d9-aea3-128f438d39e6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "HJ3IcAgOzxzM",
        "outputId": "5895c601-a5da-492b-f8e8-abf34b080d15"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Texts\n",
              "18    man shall not sleep with man is actually man s...\n",
              "1106  Fake biased CNN and leftside are dangerouse an...\n",
              "1673                             It’s not controversial\n",
              "1938  All lives can not matter if black lives don't ...\n",
              "1912  Injustice is people getting fire for telling t...\n",
              "1068  willholt11 no.. every American “singling our A...\n",
              "557   It's funny how she's turned into a virtue sign...\n",
              "1320  “Black lives matter.” Notice how it doesn’t sa...\n",
              "2188        You god doesn't agree with all lives matter\n",
              "1235                    I trust in Madonna. That's all."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d92b0f3-5e0a-441e-a3be-c03317c9d675\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>man shall not sleep with man is actually man s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1106</th>\n",
              "      <td>Fake biased CNN and leftside are dangerouse an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1673</th>\n",
              "      <td>It’s not controversial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1938</th>\n",
              "      <td>All lives can not matter if black lives don't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1912</th>\n",
              "      <td>Injustice is people getting fire for telling t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1068</th>\n",
              "      <td>willholt11 no.. every American “singling our A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>It's funny how she's turned into a virtue sign...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1320</th>\n",
              "      <td>“Black lives matter.” Notice how it doesn’t sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2188</th>\n",
              "      <td>You god doesn't agree with all lives matter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>I trust in Madonna. That's all.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d92b0f3-5e0a-441e-a3be-c03317c9d675')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d92b0f3-5e0a-441e-a3be-c03317c9d675 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d92b0f3-5e0a-441e-a3be-c03317c9d675');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.info(),end=\"\\n\\n\")\n",
        "print(df_dev.info(),end=\"\\n\\n\")\n",
        "print(df_test.info(),end=\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6XxKABC15cj",
        "outputId": "98266ef9-b9bd-48d5-ca2b-b257d5a819d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22740 entries, 0 to 22739\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Texts   22740 non-null  object\n",
            " 1   label   22740 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 355.4+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2841 entries, 0 to 2840\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Texts   2841 non-null   object\n",
            " 1   label   2841 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 44.5+ KB\n",
            "None\n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2843 entries, 0 to 2842\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Texts   2843 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 22.3+ KB\n",
            "None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map each label to an integer number, where Hope speech is considered as 1 and Non Hope speech as 0"
      ],
      "metadata": {
        "id": "Y4PZimOc0zy4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'] = df['label'].map({'Hope_speech': 1, 'Non_hope_speech': 0})"
      ],
      "metadata": {
        "id": "2v0e1_ri4Y66"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "B38-5aDX4cIt",
        "outputId": "75e4f599-720f-41c7-d8a5-3bcb120025ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   Texts  label\n",
              "10259                   @Public Public said the riot fan      0\n",
              "13600            Well it has to get to 666 at one point.      0\n",
              "9094   I feel sorry for this poor lost soul! What goo...      0\n",
              "6431                           U are such an inspiration      1\n",
              "19891  @Nely Candelario  Nely Candelario   *cough * m...      0\n",
              "4180   @ur mom is a cat victim mentality =!= being a ...      0\n",
              "8394   People are getting killed just because there M...      0\n",
              "17373                   se lo dici tu wat do that means?      0\n",
              "20601  Completely badass sherif won't take any bs... ...      0\n",
              "6550   @Rocky SinainnKim Kardashian is also multimili...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc2c5dd9-9e81-4b49-8258-38d8cfd79061\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10259</th>\n",
              "      <td>@Public Public said the riot fan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13600</th>\n",
              "      <td>Well it has to get to 666 at one point.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9094</th>\n",
              "      <td>I feel sorry for this poor lost soul! What goo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6431</th>\n",
              "      <td>U are such an inspiration</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19891</th>\n",
              "      <td>@Nely Candelario  Nely Candelario   *cough * m...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4180</th>\n",
              "      <td>@ur mom is a cat victim mentality =!= being a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8394</th>\n",
              "      <td>People are getting killed just because there M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17373</th>\n",
              "      <td>se lo dici tu wat do that means?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20601</th>\n",
              "      <td>Completely badass sherif won't take any bs... ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6550</th>\n",
              "      <td>@Rocky SinainnKim Kardashian is also multimili...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc2c5dd9-9e81-4b49-8258-38d8cfd79061')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc2c5dd9-9e81-4b49-8258-38d8cfd79061 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc2c5dd9-9e81-4b49-8258-38d8cfd79061');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['label'].value_counts() # checking the count of 0's and 1's in the dataset, i.e., Hope speech and Non hope speech."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyQoDyXm4ieQ",
        "outputId": "cf059abb-c624-4d17-b90f-a60177b298ad"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    20778\n",
              "1     1962\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "37sje2NS5EWR",
        "outputId": "27df3674-6bc4-456e-c103-dee52c94b26f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              label\n",
              "count  22740.000000\n",
              "mean       0.086280\n",
              "std        0.280783\n",
              "min        0.000000\n",
              "25%        0.000000\n",
              "50%        0.000000\n",
              "75%        0.000000\n",
              "max        1.000000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-659b3bff-88bc-4141-b4a0-4ea8e94594b7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22740.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.086280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.280783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-659b3bff-88bc-4141-b4a0-4ea8e94594b7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-659b3bff-88bc-4141-b4a0-4ea8e94594b7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-659b3bff-88bc-4141-b4a0-4ea8e94594b7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis.(EDA)**"
      ],
      "metadata": {
        "id": "LGbvSvu61yXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.label.value_counts().plot(kind='pie',autopct='%1.0f%%') # Plotting the labels of data."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "5XRddkBC5IU1",
        "outputId": "40ee3bc1-fa01-4f7d-f202-18e1fbbb6854"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8980073e50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev['label'] = df_dev['label'].map({'Hope_speech': 1, 'Non_hope_speech': 0})\n",
        "df_dev.sample(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eCDAjzuOW5a5",
        "outputId": "422a780e-0707-4cb6-a166-cee2245cbb3f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Texts  label\n",
              "906   Its been a week?  Anybody?  Democratic Liberal...      0\n",
              "1933  You forgot the dark side of this “protest” wit...      0\n",
              "1898  I don‘t think you really get what all this is ...      0\n",
              "146   @Calvinist 1689 🤣 Don't be so quick to give Tr...      0\n",
              "2463               @Sam Osler she's correct look harder      0\n",
              "547                      This woman always surprises me      0\n",
              "730                                   It is just s book      0\n",
              "865   @HooverDude 60 What kind of argument is that f...      0\n",
              "512   As Long as we keep calling ourselves black we ...      0\n",
              "114   Black Lives Don't Matter any more than Hispani...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4991f331-7fcc-478b-bff4-3550a3a226a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>Its been a week?  Anybody?  Democratic Liberal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1933</th>\n",
              "      <td>You forgot the dark side of this “protest” wit...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1898</th>\n",
              "      <td>I don‘t think you really get what all this is ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>@Calvinist 1689 🤣 Don't be so quick to give Tr...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2463</th>\n",
              "      <td>@Sam Osler she's correct look harder</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>This woman always surprises me</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>730</th>\n",
              "      <td>It is just s book</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>865</th>\n",
              "      <td>@HooverDude 60 What kind of argument is that f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>As Long as we keep calling ourselves black we ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>Black Lives Don't Matter any more than Hispani...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4991f331-7fcc-478b-bff4-3550a3a226a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4991f331-7fcc-478b-bff4-3550a3a226a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4991f331-7fcc-478b-bff4-3550a3a226a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev['label'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzkVUZzfXkRl",
        "outputId": "8e340fc1-e3c7-4547-b88b-06561fe6ba7e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2569\n",
              "1     272\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev.label.value_counts().plot(kind='pie',autopct='%1.0f%%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "c4mfkhkV49aA",
        "outputId": "37d39845-4d35-4c60-b006-8f6994f889fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f89119ad6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "THe first step is to tokenize the values.\n",
        "Transformers provides the pretrained Tokenizer. The tokenizer used here is Roberta-base"
      ],
      "metadata": {
        "id": "ZAwlYDV65Nh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = 512)"
      ],
      "metadata": {
        "id": "dVicD-Gp5Zem"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function for printing the sample text after passing into tokenizer."
      ],
      "metadata": {
        "id": "IkV-CtTc5z4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_print(text):\n",
        "  tokenized_txt=tokenizer.tokenize(text) #Passing into Tokenizer to Tokenize it.\n",
        "  Token_ids=tokenizer.convert_tokens_to_ids(tokenized_txt) #Converting tokens to Id's \n",
        "  return tokenized_txt,Token_ids"
      ],
      "metadata": {
        "id": "Z7kSgZNyYdsS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y=sample_print(df['Texts'][0])\n",
        "print(\" Texts-\",df['Texts'][0],\"\\n\",\"Tokenized_Text-\",X,\"\\n\",\"Token IDs-\",Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqSsqjf8YgHb",
        "outputId": "965482fe-5cb1-458a-c323-99405739e778"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Texts- these tiktoks radiate gay chaotic energy and i love it \n",
            " Tokenized_Text- ['these', 'Ġt', 'ik', 't', 'oks', 'Ġrad', 'iate', 'Ġgay', 'Ġchaotic', 'Ġenergy', 'Ġand', 'Ġi', 'Ġlove', 'Ġit'] \n",
            " Token IDs- [29902, 326, 967, 90, 17015, 13206, 10599, 5100, 16529, 1007, 8, 939, 657, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y=sample_print(df_dev['Texts'][0])\n",
        "print(\" Texts-\",df_dev['Texts'][0],\"\\n\",\"Tokenized_Text-\",X,\"\\n\",\"Token IDs-\",Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF5gKLNaJWJh",
        "outputId": "f442c780-32cf-45b1-ccea-a78f4375e6a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Texts- Thats it.... like....I dont like that statue \n",
            " Tokenized_Text- ['Th', 'ats', 'Ġit', '....', 'Ġlike', '....', 'I', 'Ġdont', 'Ġlike', 'Ġthat', 'Ġstatue'] \n",
            " Token IDs- [11329, 2923, 24, 17220, 101, 17220, 100, 33976, 101, 14, 9577]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_t=df['Texts'].tolist() #converting it to list for passing the whole dataset at a time\n",
        "data_v=df_dev['Texts'].tolist()"
      ],
      "metadata": {
        "id": "MFZxjxWiLAqG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tokenized=tokenizer(data_t, padding=True, truncation=True, max_length=512)\n",
        "y_train=df['label'].to_list()\n",
        "X_val_tokenized=tokenizer(data_v, padding=True, truncation=True, max_length=512)\n",
        "y_val=df_dev['label'].to_list()"
      ],
      "metadata": {
        "id": "ycVKAoqKEmii"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):    \n",
        "    def __init__(self, encodings, labels=None):          \n",
        "        self.encodings = encodings        \n",
        "        self.labels = labels\n",
        "     \n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "    def __len__(self):\n",
        "        return len(self.encodings[\"input_ids\"])"
      ],
      "metadata": {
        "id": "NVuC45b_EFI1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(X_train_tokenized,y_train)\n",
        "val_dataset = Dataset(X_val_tokenized,y_val)"
      ],
      "metadata": {
        "id": "4T7Y4IM_HSgn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **MODEL**"
      ],
      "metadata": {
        "id": "74Mx9uKEHU2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "configuration = RobertaConfig()\n",
        "model = RobertaForSequenceClassification.from_pretrained('roberta-base')\n",
        "configuration = model.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJorxpFDqFhG",
        "outputId": "109d2c16-d83e-464a-9b0b-e229c6a658ee"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configuration"
      ],
      "metadata": {
        "id": "RLeI0m7QqeUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02a87099-ab77-47ca-8871-6f8bbb82bdc0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaConfig {\n",
              "  \"_name_or_path\": \"roberta-base\",\n",
              "  \"architectures\": [\n",
              "    \"RobertaForMaskedLM\"\n",
              "  ],\n",
              "  \"attention_probs_dropout_prob\": 0.1,\n",
              "  \"bos_token_id\": 0,\n",
              "  \"classifier_dropout\": null,\n",
              "  \"eos_token_id\": 2,\n",
              "  \"hidden_act\": \"gelu\",\n",
              "  \"hidden_dropout_prob\": 0.1,\n",
              "  \"hidden_size\": 768,\n",
              "  \"initializer_range\": 0.02,\n",
              "  \"intermediate_size\": 3072,\n",
              "  \"layer_norm_eps\": 1e-05,\n",
              "  \"max_position_embeddings\": 514,\n",
              "  \"model_type\": \"roberta\",\n",
              "  \"num_attention_heads\": 12,\n",
              "  \"num_hidden_layers\": 12,\n",
              "  \"pad_token_id\": 1,\n",
              "  \"position_embedding_type\": \"absolute\",\n",
              "  \"transformers_version\": \"4.18.0\",\n",
              "  \"type_vocab_size\": 1,\n",
              "  \"use_cache\": true,\n",
              "  \"vocab_size\": 50265\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "I63HW7J9q7uR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a1b1584-36cd-4377-aa11-086eed797fe1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./result\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=4,\n",
        "    do_predict=True,\n",
        ")"
      ],
      "metadata": {
        "id": "EFFEwtrG8h2K"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "model,\n",
        "training_args,\n",
        "train_dataset=train_dataset,\n",
        "eval_dataset=val_dataset,\n",
        "tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "p71cRxNH70vw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a61ub1ue-Zr7",
        "outputId": "34d1370e-65c9-4f51-d251-f1b39b050f8a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 22740\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 5688\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5688' max='5688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5688/5688 2:25:52, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.210600</td>\n",
              "      <td>0.190423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.163200</td>\n",
              "      <td>0.219315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.125200</td>\n",
              "      <td>0.285602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.071600</td>\n",
              "      <td>0.352087</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to ./result/checkpoint-500\n",
            "Configuration saved in ./result/checkpoint-500/config.json\n",
            "Model weights saved in ./result/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-1000\n",
            "Configuration saved in ./result/checkpoint-1000/config.json\n",
            "Model weights saved in ./result/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2841\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./result/checkpoint-1500\n",
            "Configuration saved in ./result/checkpoint-1500/config.json\n",
            "Model weights saved in ./result/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-2000\n",
            "Configuration saved in ./result/checkpoint-2000/config.json\n",
            "Model weights saved in ./result/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-2500\n",
            "Configuration saved in ./result/checkpoint-2500/config.json\n",
            "Model weights saved in ./result/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2841\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./result/checkpoint-3000\n",
            "Configuration saved in ./result/checkpoint-3000/config.json\n",
            "Model weights saved in ./result/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-3000/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-3500\n",
            "Configuration saved in ./result/checkpoint-3500/config.json\n",
            "Model weights saved in ./result/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-4000\n",
            "Configuration saved in ./result/checkpoint-4000/config.json\n",
            "Model weights saved in ./result/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-4000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2841\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./result/checkpoint-4500\n",
            "Configuration saved in ./result/checkpoint-4500/config.json\n",
            "Model weights saved in ./result/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-4500/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-5000\n",
            "Configuration saved in ./result/checkpoint-5000/config.json\n",
            "Model weights saved in ./result/checkpoint-5000/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-5000/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-5000/special_tokens_map.json\n",
            "Saving model checkpoint to ./result/checkpoint-5500\n",
            "Configuration saved in ./result/checkpoint-5500/config.json\n",
            "Model weights saved in ./result/checkpoint-5500/pytorch_model.bin\n",
            "tokenizer config file saved in ./result/checkpoint-5500/tokenizer_config.json\n",
            "Special tokens file saved in ./result/checkpoint-5500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2841\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=5688, training_loss=0.14478315884553933, metrics={'train_runtime': 8754.4603, 'train_samples_per_second': 10.39, 'train_steps_per_second': 0.65, 'total_flos': 1.28076706194912e+16, 'train_loss': 0.14478315884553933, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction"
      ],
      "metadata": {
        "id": "Rbjjjaz7oqDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(val_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "5SFB-oKBKk_J",
        "outputId": "41a6c233-9d4e-4056-c87a-340acd669246"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 2841\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='356' max='178' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [178/178 02:25]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true=df_dev['label']"
      ],
      "metadata": {
        "id": "EiEN_EF6-oH-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "3P_l9PGVKxMw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,accuracy_score,precision_score,recall_score\n",
        "print(classification_report(y_true, y_preds))\n",
        "print(accuracy_score(y_true,y_preds))\n",
        "print(precision_score(y_true,y_preds,average='macro'))\n",
        "print(recall_score(y_true,y_preds,average='macro'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oBLRZhC-xEy",
        "outputId": "0e925a92-2780-4dcd-e1f8-9842f54419df"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      2569\n",
            "           1       0.62      0.66      0.64       272\n",
            "\n",
            "    accuracy                           0.93      2841\n",
            "   macro avg       0.79      0.81      0.80      2841\n",
            "weighted avg       0.93      0.93      0.93      2841\n",
            "\n",
            "0.9292502639915523\n",
            "0.7936399553614062\n",
            "0.8080242655645364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "id": "VhQqpSbu-qp2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "6d4cf173-cef7-4094-964e-51f86dc60407"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  Texts  label\n",
              "0                  What do you mean by the word sniped?      0\n",
              "1     I love this video!! I’m bisexual and it’s just...      1\n",
              "2     ya the irony but then i don't want to come off...      0\n",
              "3                A PERSON'S CHARACTER MATTERS. PERIOD!!      1\n",
              "4                                   @Blaster of Gasters      0\n",
              "...                                                 ...    ...\n",
              "2838  +Ashrenneemakeup I think it's all a deliberate...      0\n",
              "2839         Sheriff David Clarke. This guy is amazing.      0\n",
              "2840                            Abandorn Hope Situation      0\n",
              "2841  Sheriff Clarke you are a person of such strong...      0\n",
              "2842  Sanders has no room to talk. If there's one pe...      0\n",
              "\n",
              "[2843 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa31e262-d56f-4d76-ac2b-ce631e9f84b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texts</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What do you mean by the word sniped?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love this video!! I’m bisexual and it’s just...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ya the irony but then i don't want to come off...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A PERSON'S CHARACTER MATTERS. PERIOD!!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Blaster of Gasters</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2838</th>\n",
              "      <td>+Ashrenneemakeup I think it's all a deliberate...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2839</th>\n",
              "      <td>Sheriff David Clarke. This guy is amazing.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2840</th>\n",
              "      <td>Abandorn Hope Situation</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2841</th>\n",
              "      <td>Sheriff Clarke you are a person of such strong...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2842</th>\n",
              "      <td>Sanders has no room to talk. If there's one pe...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2843 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa31e262-d56f-4d76-ac2b-ce631e9f84b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa31e262-d56f-4d76-ac2b-ce631e9f84b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa31e262-d56f-4d76-ac2b-ce631e9f84b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_test=df_test['Texts'].tolist()\n",
        "X_test_tokenized=tokenizer(data_test, padding=True, truncation=True, max_length=512)\n",
        "test_dataset=Dataset(X_test_tokenized)"
      ],
      "metadata": {
        "id": "n9LuwOdMIiHa"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "WLWVw8MVGQUK",
        "outputId": "d6807cdd-7f84-4797-bca8-17a108beb098"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 2843\n",
            "  Batch size = 16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='534' max='178' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [178/178 03:33]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "pXu3GFKps0ai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.argmax(predictions.predictions, axis=-1)"
      ],
      "metadata": {
        "id": "l8GksAW7KdVV"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['label']=preds.tolist()\n",
        "df_test.to_csv(\"final_result.tsv\", sep = \"\\t\")"
      ],
      "metadata": {
        "id": "zzQxAQBmKMP4"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_test['label'])\n",
        "print(df_test['label'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtkLvzyu-98Z",
        "outputId": "94514ce4-a936-4e48-cb83-761825d7ca86"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0\n",
            "1       1\n",
            "2       0\n",
            "3       1\n",
            "4       0\n",
            "       ..\n",
            "2838    0\n",
            "2839    0\n",
            "2840    0\n",
            "2841    0\n",
            "2842    0\n",
            "Name: label, Length: 2843, dtype: int64\n",
            "0    2560\n",
            "1     283\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}